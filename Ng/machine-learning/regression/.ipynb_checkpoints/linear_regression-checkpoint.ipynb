{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 梯度下降\n",
    "\n",
    "\n",
    "### 伪代码：\n",
    "\n",
    "- bgd\n",
    "> 优化代价函数是所有关于数据样本的loss，计算整个样本的loss后才更新权值，m为所有样本数量和\n",
    "\n",
    "    初始权值，迭代次数,单次误差，总误差数组，每一次迭代权值矩阵\n",
    "    收敛flag：converged\n",
    "    while 迭代中\n",
    "        if flag: 结束\n",
    "        for 每一个权值，\n",
    "            梯度下降公式，计算每一个下降梯度\n",
    "        更新$\\theta_j$\n",
    "        计算损失函数J\n",
    "        if 误差小于精度：\n",
    "            flag为真\n",
    "    返回\n",
    "  \n",
    "- sgd\n",
    "> 优化的代价函数是单个数据样本的loss，计算每个样本的loss后就可以立即更新权值，即m=1\n",
    "\n",
    "    初始权值，迭代次数,单次误差，总误差数组，每一次迭代权值矩阵\n",
    "    收敛flag：converged\n",
    "    while 迭代中\n",
    "        if flag: 结束\n",
    "        for 每一个权值，\n",
    "            梯度下降公式，计算$\\theta_j$\n",
    "        计算损失函数J\n",
    "        if 误差小于精度：\n",
    "            flag为真\n",
    "    返回\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "def exe_time(func):\n",
    "    \"\"\" 耗时计算装饰器 \n",
    "    \"\"\"\n",
    "    def new_func(*args, **args2):\n",
    "        t0 = time.time()\n",
    "        back = func(*args, **args2)\n",
    "        return back, time.time() - t0\n",
    "    return new_func\n",
    "\n",
    "def load_dataset(filename):\n",
    "    \"\"\" 读取数据\n",
    "    数据格式如下：\n",
    "    “f1 tab f2 tab f3 tab label\"\n",
    "    \n",
    "    Args:\n",
    "        filename\n",
    "    Returns:\n",
    "        X: 训练样本集矩阵\n",
    "        y: 标签集矩阵\n",
    "    \"\"\"\n",
    "    pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAADeVJREFUeJzt3W2MZQdZwPH/48wis5U6rTtFdrdx\nwcCgFuzW0RSoqC3NNtK0G+KHGmuqkjQhBkqjg11JNHyCMEThE2ZToY00JVjHgTTKtikqfpCa2U7L\nFrZjjZR2Zws7hIwanNBlefxw79Tdcd/u25w7z/x/yebeOXPunCe7d/5757zcicxEkrT5/UjTA0iS\n+sOgS1IRBl2SijDoklSEQZekIgy6JBVh0CWpCIMuSUUYdEkqYnQjN7Zjx47cs2fPRm5Skja9w4cP\nfyczJy603oYGfc+ePczPz2/kJiVp04uIb17Meu5ykaQiDLokFWHQJakIgy5JRRh0SSpiQ89ykaSt\nZG5hiZlDixxfWWXn+BjT+ybZv3fXwLZn0CVpAOYWljgwe4TVk6cAWFpZ5cDsEYCBRd1dLpI0ADOH\nFl+O+ZrVk6eYObQ4sG0adEkagOMrqx0t7weDLkkDsHN8rKPl/WDQJWkApvdNMrZt5IxlY9tGmN43\nObBtelBUkgZg7cCnZ7lIUgH79+4aaMDXc5eLJBVh0CWpCIMuSUUYdEkqwqBLUhEGXZKKMOiSVIRB\nl6QiDLokFWHQJakIgy5JRRh0SSrCoEtSEQZdkoow6JJUhEGXpCIMuiQVYdAlqQiDLklFGHRJKuKC\nQY+IT0XEiYh4+rRll0fEoxHxbPv2ssGOKUm6kIt5hX4fcNO6ZfcAj2Xm64HH2h9Lkhp0waBn5peB\n765bfCtwf/v+/cD+Ps8lSepQt/vQX52ZLwK0b6/o30iSpG4M/KBoRNwZEfMRMb+8vDzozUnSltVt\n0L8dEa8BaN+eONeKmXkwM6cyc2piYqLLzUmSLqTboH8BuKN9/w7g8/0ZR5LUrYs5bfFB4F+AyYg4\nFhHvBj4C3BgRzwI3tj+WJDVo9EIrZOZvnuNTN/R5FklSD7xSVJKKMOiSVIRBl6QiDLokFWHQJakI\ngy5JRRh0SSrCoEtSEQZdkoow6JJUhEGXpCIMuiQVYdAlqQiDLklFGHRJKsKgS1IRBl2SijDoklSE\nQZekIgy6JBVh0CWpCIMuSUUYdEkqwqBLUhEGXZKKMOiSVIRBl6QiDLokFWHQJakIgy5JRRh0SSrC\noEtSEQZdkoow6JJUhEGXpCJ6CnpE3B0RX4uIpyPiwYh4Zb8GkyR1puugR8Qu4H3AVGZeBYwAt/Vr\nMElSZ3rd5TIKjEXEKLAdON77SJKkbox2+8DMXIqIjwHPA6vAI5n5SN8mk7awuYUlZg4tcnxllZ3j\nY0zvm2T/3l1Nj6Uh18sul8uAW4HXAjuBSyLi9rOsd2dEzEfE/PLycveTSlvE3MISB2aPsLSySgJL\nK6scmD3C3MJS06NpyPWyy+UdwDcyczkzTwKzwFvXr5SZBzNzKjOnJiYmetictDXMHFpk9eSpM5at\nnjzFzKHFhibSZtFL0J8Hro2I7RERwA3A0f6MJW1dx1dWO1ourek66Jn5OPAQ8ARwpP21DvZpLmnL\n2jk+1tFyaU1PZ7lk5p9m5hsz86rM/O3M/H6/BpO2qul9k4xtGzlj2di2Eab3TTY0kTaLrs9ykTQY\na2ezeJaLOmXQpSG0f+8uA66O+V4uklSEQZekIgy6JBVh0CWpCIMuSUUYdEkqwqBLUhEGXZKKMOiS\nVIRBl6QiDLokFWHQJakIgy5JRRh0SSrCoEtSEQZdkoow6JJUhEGXpCIMuiQVYdAlqQiDLklFGHRJ\nKsKgS1IRBl2SijDoklSEQZekIgy6JBVh0CWpCIMuSUUYdEkqwqBLUhEGXZKKMOiSVERPQY+I8Yh4\nKCKeiYijEfGWfg0mSerMaI+P/wTwxcz8jYh4BbC9DzNJkrrQddAj4lLg7cDvAGTmS8BL/RlLktSp\nXna5vA5YBj4dEQsRcW9EXNKnuSRJHeol6KPANcAnM3Mv8D3gnvUrRcSdETEfEfPLy8s9bE6SdD69\nBP0YcCwzH29//BCtwJ8hMw9m5lRmTk1MTPSwOUnS+XQd9Mz8FvBCREy2F90AfL0vU0mSOtbrWS7v\nBR5on+HyH8Dv9j6SJKkbPQU9M58Epvo0iySpB14pKklFGHRJKsKgS1IRBl2SijDoklSEQZekIgy6\nJBVh0CWpCIMuSUUYdEkqwqBLUhEGXZKKMOiSVIRBl6QiDLokFWHQJakIgy5JRRh0SSrCoEtSEQZd\nkoow6JJUhEGXpCIMuiQVYdAlqQiDLklFGHRJKsKgS1IRBl2SijDoklSEQZekIgy6JBVh0CWpCIMu\nSUUYdEkqwqBLUhE9Bz0iRiJiISIe7sdAkqTu9OMV+l3A0T58HUlSD3oKekTsBt4J3NufcSRJ3Rrt\n8fEfBz4AvKoPs6iwuYUlZg4tcnxllZ3jY0zvm2T/3l1NjyWV0vUr9Ii4GTiRmYcvsN6dETEfEfPL\ny8vdbk6b2NzCEgdmj7C0skoCSyurHJg9wtzCUtOjSaX0ssvlbcAtEfEc8Fng+oj4zPqVMvNgZk5l\n5tTExEQPm9NmNXNokdWTp85YtnryFDOHFhuaSKqp66Bn5oHM3J2Ze4DbgC9l5u19m0xlHF9Z7Wi5\npO54HroGbuf4WEfLJXWnL0HPzH/MzJv78bVUz/S+Sca2jZyxbGzbCNP7JhuaSKqp17NcpAtaO5vF\ns1ykwTLo2hD79+4y4NKAuQ9dkorwFXoxXsAjbV0GvZC1C3jWzvleu4AHMOrSFuAul0K8gEfa2gx6\nIV7AI21tBr0QL+CRtjaDXogX8EhbmwdFC/ECHmlrM+jFeAGPtHW5y0WSijDoklSEQZekIgy6JBVh\n0CWpCIMuSUUYdEkqwqBLUhEGXZKKMOiSVIRBl6QiDLokFWHQJakIgy5JRRh0SSrCoEtSEQZdkoow\n6JJUxND/Crq5hSV/R6YkXYShDvrcwhIHZo+wevIUAEsrqxyYPQJg1CVpnaHe5TJzaPHlmK9ZPXmK\nmUOLDU0kScNrqIN+fGW1o+WStJUNddB3jo91tFyStrKhDvr0vknGto2csWxs2wjT+yYbmkiShlfX\nQY+IKyPiHyLiaER8LSLu6udg0Drw+eF3vYld42MEsGt8jA+/600eEJWks+jlLJcfAH+QmU9ExKuA\nwxHxaGZ+vU+zAa2oG3BJurCuX6Fn5ouZ+UT7/n8DRwHLK0kN6cs+9IjYA+wFHu/H15Mkda7noEfE\njwF/A7w/M//rLJ+/MyLmI2J+eXm5181Jks6hp6BHxDZaMX8gM2fPtk5mHszMqcycmpiY6GVzkqTz\n6OUslwD+EjiamX/Wv5EkSd2IzOzugRHXAf8MHAF+2F78x5n5d+d5zDLwza42CDuA73T52EFyrs44\nV2ecqzNV5/qpzLzgLo6ug77RImI+M6eanmM95+qMc3XGuTqz1eca6itFJUkXz6BLUhGbKegHmx7g\nHJyrM87VGefqzJaea9PsQ5cknd9meoUuSTqPoQ/6RryrY7ciYiQiFiLi4aZnOV1EjEfEQxHxTPvv\n7S1NzwQQEXe3/w2fjogHI+KVDc3xqYg4ERFPn7bs8oh4NCKebd9eNiRzzbT/Hb8aEX8bEePDMNdp\nn/vDiMiI2DEsc0XEeyNisf1c++gwzBURV0fEVyLiyfaV8780iG0PfdD5v3d1/BngWuD3I+JnG55p\nzV203pRs2HwC+GJmvhH4eYZgxojYBbwPmMrMq4AR4LaGxrkPuGndsnuAxzLz9cBj7Y832n38/7ke\nBa7KzDcD/wYc2OihOPtcRMSVwI3A8xs9UNt9rJsrIn4NuBV4c2b+HPCxYZgL+Cjwocy8GviT9sd9\nN/RBH9Z3dYyI3cA7gXubnuV0EXEp8HZaV/GSmS9l5kqzU71sFBiLiFFgO3C8iSEy88vAd9ctvhW4\nv33/fmD/hg7F2efKzEcy8wftD78C7B6Gudr+HPgA0MiBuHPM9R7gI5n5/fY6J4ZkrgQubd//cQb0\n3B/6oJ9uyN7V8eO0nsw/vNCKG+x1wDLw6fbuoHsj4pKmh8rMJVqvlp4HXgT+MzMfaXaqM7w6M1+E\n1osI4IqG5zmb3wP+vukhACLiFmApM59qepZ13gD8ckQ8HhH/FBG/2PRAbe8HZiLiBVrfBwP5SWvT\nBP1C7+q4wbPcDJzIzMNNznEOo8A1wCczcy/wPZrZfXCG9j7pW4HXAjuBSyLi9man2jwi4oO0dj8+\nMASzbAc+SGvXwbAZBS6jtXt2Gvhc+32nmvYe4O7MvBK4m/ZP0P22KYJ+Me/quMHeBtwSEc8BnwWu\nj4jPNDvSy44BxzJz7aeYh2gFvmnvAL6RmcuZeRKYBd7a8Eyn+3ZEvAagfbvhP6qfS0TcAdwM/FYO\nx3nGP03rP+an2t8Du4EnIuInG52q5Rgwmy3/Susn6A0/YHsWd9B6zgP8NbA1D4oO47s6ZuaBzNyd\nmXtoHdj7UmYOxavNzPwW8EJErP0m7RuAvv5awC49D1wbEdvb/6Y3MAQHa0/zBVrfdLRvP9/gLC+L\niJuAPwJuycz/aXoegMw8kplXZOae9vfAMeCa9nOvaXPA9QAR8QbgFQzHm3UdB36lff964NmBbCUz\nh/oPcB2tAwpfBZ5s//n1puc6bb5fBR5ueo51M10NzLf/zuaAy5qeqT3Xh4BngKeBvwJ+tKE5HqS1\nH/8krRi9G/gJWme3PNu+vXxI5vp34IXTnvt/MQxzrfv8c8COYZiLVsA/036OPQFcPyRzXQccBp6i\ndQzwFwaxba8UlaQihn6XiyTp4hh0SSrCoEtSEQZdkoow6JJUhEGXpCIMuiQVYdAlqYj/BWWAZhTw\n9qgNAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10bd995f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 创建数据\n",
    "X = np.array([[1, 2], [1, 6], [1, 8], [1,12], [1,18]])\n",
    "y = np.array([[2.3],[3.5],[3.9],[7.9],[11.3]])\n",
    "m, n = X.shape\n",
    "theta_ground = np.array([[1],[1]])\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(X[:,1],y,'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def h(theta, x):\n",
    "    \"\"\"预测函数\n",
    "    \n",
    "    Args:\n",
    "        theta: 相关系数矩阵\n",
    "        x: 特征矩阵\n",
    "   Return:\n",
    "       预测结果\n",
    "    \"\"\"\n",
    "    return (x @ theta)\n",
    "\n",
    "def J(theta, X, y):\n",
    "    \"\"\"代价函数\n",
    "    \n",
    "    Args:\n",
    "        theta: 相关系数矩阵\n",
    "        X: 样本集矩阵\n",
    "        y: 标签集矩阵\n",
    "        \n",
    "    Return:\n",
    "        预测误差\n",
    "    \"\"\"\n",
    "    m = X.shape[0]\n",
    "    return (X @ theta - y).T @ (X @ theta - y) / (2*m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@exe_time\n",
    "def bgd(X, y, learning_rate = 0.01, max_loop = 1000, epsilon = 0.001):\n",
    "    \"\"\"批量梯度下降\n",
    "    \n",
    "    Args:\n",
    "        rate: 学习率\n",
    "        max_loop： 最大迭代次数\n",
    "        epsilon： 收敛精度\n",
    "    Return:\n",
    "        (theta, errors, thetas), time_consumed\n",
    "    \"\"\"\n",
    "    m, n = X.shape  #m 为样本数，  n为特征数\n",
    "    theta = np.zeros((n, 1))\n",
    "    thetas = []\n",
    "    error = float('inf')\n",
    "    errors = []\n",
    "    counts = 0   \n",
    "    while counts < max_loop and error > epsilon:\n",
    "        counts += 1\n",
    "        tmp = np.zeros((n,1))\n",
    "        for j in range(n):\n",
    "            deriv = (X@theta - y).T @ X[:,j] / m\n",
    "            tmp[j] = theta[j] - learning_rate * deriv\n",
    "        theta = tmp\n",
    "        thetas.append(theta.tolist())        \n",
    "        error = J(theta, X, y) \n",
    "        errors.append(error.tolist())\n",
    "    return theta, thetas, errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#暂时不清楚问题原因\n",
    "\n",
    "@exe_time\n",
    "def sgd(X, y, learning_rate=0.01, max_loop=1000, epsilon=0.001):\n",
    "    \"\"\"随机梯度下降\n",
    "    \"\"\"\n",
    "    m, n = X.shape\n",
    "    theta = np.zeros((n,1))\n",
    "    thetas = []\n",
    "    error = float('inf')\n",
    "    errors = []\n",
    "    count = 0 \n",
    "    converged = False\n",
    "    while count < max_loop:\n",
    "        if converged:\n",
    "            break\n",
    "        count += 1\n",
    "        for i in range(m):\n",
    "            if converged:\n",
    "                break\n",
    "            diff = h(theta, X[i].T) - y[i]\n",
    "            tmp = np.zeros((n,1))\n",
    "            for j in range(n):\n",
    "                tmp[j] = theta[j] - learning_rate * diff * X[i,j]\n",
    "            theta = tmp\n",
    "            thetas.append(theta.tolist())\n",
    "            error = J(theta, X, y)\n",
    "            errors.append(error.tolist())\n",
    "            if error < epsilon:\n",
    "                converged = True\n",
    "    return theta, thetas, errors\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[ 0.25334077],\n",
      "       [ 0.60025883]]), array([[ 0.24321843]])) 0.06715798377990723\n",
      "(array([[ 1.9822039 ],\n",
      "       [ 0.34019209]]), array([[ 1.46241973]])) 0.14585280418395996\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.ticker as mtick\n",
    "import numpy as np\n",
    "\n",
    "learning_rate = 0.01\n",
    "max_loop =1000\n",
    "epsilon = 0.001\n",
    "\n",
    "result, time_consumed = bgd(X, y, learning_rate, max_loop, epsilon)\n",
    "theta, thetas, errors = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-90a56269813e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 绘制拟合曲线\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfitting_fig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtitle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"bgd: learning_rate=%.2f, max_loop=%d, epsilon=%.3f \\n time: %ds \"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_loop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_consumed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfitting_fig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m111\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#training_set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# 绘制拟合曲线\n",
    "fitting_fig = plt.figure()\n",
    "title = \"bgd: learning_rate=%.2f, max_loop=%d, epsilon=%.3f \\n time: %ds \" %(learning_rate, max_loop, epsilon, time_consumed)\n",
    "ax = fitting_fig.add_subplot(111, title=title)\n",
    "#training_set\n",
    "yi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    X, y = load_dataset('data/ex1.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
