{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  线性回归实现\n",
    "\n",
    "针对简单线性模型，求解 $y(x_0,x_1,...,x_n) = w_0w_0+w_1x_1+...+w_nx_n+b$\n",
    "\n",
    "$x_n$为第n个属性\n",
    "\n",
    "写成矩阵形式:\n",
    "\n",
    " $X=[{x_0,x_1,...,x_n，1}],  \\theta=[{w_0,w_1,...,w_n,b}]^T$\n",
    "\n",
    "$y = X\\theta$ \n",
    "\n",
    "\n",
    "代价函数(Cost Function):\n",
    "$$J(w_0,w_1,...,w_n,b) = \\frac{1}{2m}\\sum_{i=1}^m(y_i-w_ix_i-b)^2 = \\frac{1}{2m}(y-X\\theta)^T(y-X\\theta)$$\n",
    "\n",
    "均方误差 $(w^*,b^*) = argmin\\sum_{i=1}^m(y_i-wx^i-b)^2$\n",
    "\n",
    "梯度下降法求解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib import pyplot plt\n",
    "import pylab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "groundtruth_weight: \n",
      "[[ 0.62472515]\n",
      " [ 0.68910792]\n",
      " [ 0.27349391]\n",
      " [ 0.43104141]]\n"
     ]
    }
   ],
   "source": [
    "#输入：数据集数目，权重数目\n",
    "#输出：真实X，y\n",
    "def generate_dataset( data_num, weight_num ):\n",
    "    x = np.random.random((data_num, weight_num))\n",
    "    X = np.c_[x, np.ones((data_num, 1))]     #添加全为1的列向量\n",
    "    theta = np.random.random((weight_num+1, 1))\n",
    "    mu, sigma = 0, 0.1    #均值，方差\n",
    "    noise = np.random.normal(mu, sigma, (data_num, 1))\n",
    "    y = X.dot(theta) + noise\n",
    "    print(\"groundtruth_weight: \")\n",
    "    print(theta)\n",
    "    return X, y, theta\n",
    "\n",
    "X, y, theta = generate_dataset( 5, 3 )\n",
    "#print(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 1)\n",
      "[[ 0.00125174]]\n"
     ]
    }
   ],
   "source": [
    "def compute_cost( X, y, theta ):\n",
    "    \n",
    "    m = len(y)\n",
    "    cost = np.transpose(y -  X.dot(theta)) @ (y -  X.dot(theta))/(2*m)   # x@y 等价于x.dot(y)  or  x.matmul(y)\n",
    "    return cost\n",
    "\n",
    "#cost = compute_cost( X, y, theta)\n",
    "#print(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.80457494],\n",
       "       [ 0.83312121],\n",
       "       [ 0.32289208],\n",
       "       [ 0.2302967 ]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gamma: 步长系数\n",
    "#eps: 终止条件\n",
    "#max_iter: 最大迭代次数\n",
    "\n",
    "def linear_regression( X, y, method=\"closed_form\", gamma=0.001, eps=0.0001, max_iter=10000):\n",
    "    #使得w最小\n",
    "    #如果method == \"closed_form\": 则用闭式解方法求出w，不需要后面三个参数\n",
    "    #如果method == \"gd\": 则用梯度下降法求解\n",
    "    \n",
    "    if method == \"closed_form\":\n",
    "        return linear_regression_by_closed_form( X, y )\n",
    "    if method == \"gd\":\n",
    "        return linear_regression_by_gd( X, y, gamma, eps, max_iter )\n",
    "    \n",
    "    print ( \"args error\" )\n",
    "    \n",
    "def linear_regression_by_closed_form( X, y ):\n",
    "    #见西瓜书式3.11\n",
    "    theta = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)\n",
    "    return w\n",
    "\n",
    "def linear_regression_by_gd( X, y, gamma=0.001, eps=0.0001, max_iter=10000 ):\n",
    "    \n",
    "    \n",
    "w = linear_regression(X,y)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 对数线性回归\n",
    "\n",
    "def log_regression(X, y, method=\"gd\", gamma=0.001, eps=0.001, max_iter=10000):\n",
    "    ln_y = np.log(y)\n",
    "    return linear_regression(X, ln_y, method, gamma, eps, max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logistic_regression(X, y, method=\"gd\", gamma=0.001, eps=0.001, max_iter=10000):\n",
    "    ln_y = np.log(y)\n",
    "    return linear_regression(X, ln_y, method, gamma, eps, max_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 代价函数更新权值优化方法\n",
    "1. 批量梯度下降：batch gradient descent\n",
    "2. 随机梯度下降\n",
    "3. 小批量随机梯度下降"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_gradient_descent():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def optimizer():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "画出散点图\n",
    "def plot_data(x, y):\n",
    "    plt.scatter(x,y)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    li"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
